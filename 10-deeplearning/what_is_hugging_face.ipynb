{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ¿Qué es Hugging Face?\n",
        "\n",
        "Hugging Face es una plataforma que democratiza el acceso a la inteligencia artificial, especialmente en el procesamiento de lenguaje natural (NLP). Es como el \"GitHub de la IA\" donde puedes encontrar, usar y compartir modelos pre-entrenados.\n",
        "\n",
        "## ¿Qué aprenderás?\n",
        "\n",
        "- Qué es Hugging Face y por qué es importante\n",
        "- Cómo usar modelos pre-entrenados\n",
        "- Conceptos básicos de transformers\n",
        "- Aplicaciones prácticas en análisis de datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ¿Qué es Hugging Face?\n",
        "\n",
        "Hugging Face es una empresa y plataforma que se ha convertido en el estándar para el desarrollo de aplicaciones de IA, especialmente en procesamiento de lenguaje natural (NLP). Su misión es democratizar la IA haciendo que sea accesible para todos.\n",
        "\n",
        "### Características principales:\n",
        "- **Modelos pre-entrenados**: Miles de modelos listos para usar\n",
        "- **Transformers**: Librería de Python para trabajar con modelos de IA\n",
        "- **Datasets**: Colección de datasets para entrenar modelos\n",
        "- **Spaces**: Plataforma para compartir aplicaciones de IA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ¿Por qué es importante para análisis de datos?\n",
        "\n",
        "### Ventajas para analistas de datos:\n",
        "\n",
        "1. **Acceso inmediato a IA avanzada**: Sin necesidad de entrenar modelos desde cero\n",
        "2. **Modelos especializados**: Para tareas específicas como análisis de sentimientos\n",
        "3. **Fácil integración**: Se integra perfectamente con pandas y scikit-learn\n",
        "4. **Actualizaciones constantes**: Modelos que mejoran continuamente\n",
        "5. **Comunidad activa**: Soporte y ejemplos de la comunidad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Casos de uso en análisis de datos\n",
        "\n",
        "A continuación veremos ejemplos prácticos de cómo usar Hugging Face para diferentes tareas de procesamiento de lenguaje natural.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Análisis de Sentimientos\n",
        "\n",
        "El análisis de sentimientos permite determinar si un texto expresa una opinión positiva, negativa o neutra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9a01df1c0394667a81a62e3f29580bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b04ce10733ef49adb4a1abf15e8ec426",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65e729ce7bb44f419e94aa4f339b6850",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aae77ef834447c3ac9a9a4253a78317",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Análisis de Sentimientos:\n",
            "\n",
            "Texto: Me encanta este producto! Es increíble.\n",
            "Resultado: NEGATIVE (confianza: 0.9364)\n",
            "\n",
            "Texto: No me gustó para nada, muy decepcionado.\n",
            "Resultado: NEGATIVE (confianza: 0.9933)\n",
            "\n",
            "Texto: El servicio fue aceptable, nada especial.\n",
            "Resultado: NEGATIVE (confianza: 0.9652)\n",
            "\n",
            "Texto: Hugging Face es una herramienta fantástica para IA.\n",
            "Resultado: POSITIVE (confianza: 0.9963)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ejemplo práctico: Análisis de Sentimientos\n",
        "\n",
        "Usaremos un pipeline pre-entrenado de Hugging Face para analizar el sentimiento\n",
        "de diferentes textos. Este modelo ha sido entrenado en millones de ejemplos\n",
        "y puede detectar sentimientos en múltiples idiomas.\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Crear pipeline de análisis de sentimientos\n",
        "# El modelo se descarga automáticamente la primera vez que se ejecuta\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Analizar diferentes textos\n",
        "textos = [\n",
        "    \"Me encanta este producto! Es increíble.\",\n",
        "    \"No me gustó para nada, muy decepcionado.\",\n",
        "    \"El servicio fue aceptable, nada especial.\",\n",
        "    \"Hugging Face es una herramienta fantástica para IA.\",\n",
        "]\n",
        "\n",
        "print(\"Análisis de Sentimientos:\\n\")\n",
        "for texto in textos:\n",
        "    result = sentiment_analyzer(texto)\n",
        "    print(f\"Texto: {texto}\")\n",
        "    print(f\"Resultado: {result[0]['label']} (confianza: {result[0]['score']:.4f})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Clasificación de Texto (Zero-Shot)\n",
        "\n",
        "La clasificación zero-shot permite clasificar texto en categorías sin necesidad de entrenar un modelo específico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daf9473ab8ff498898465a6a56546936",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf22f7c986f4f5e8f0f1cc501df8f60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df2899ddd7e4463399d32a1dde1ce5ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7060fe5ac9c84bcb8260901147a671be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6abed298f2984d1ea013e0fd611e001e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca92eb4349043de8bf3500120302431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clasificación Zero-Shot:\n",
            "\n",
            "Texto: El equipo ganó el partido 3-0 en el último minuto\n",
            "Mejor categoría: deportes (confianza: 0.2503)\n",
            "Top 3 categorías:\n",
            "  - deportes: 0.2503\n",
            "  - economía: 0.2326\n",
            "  - política: 0.2162\n",
            "\n",
            "Texto: La nueva ley fue aprobada por el congreso\n",
            "Mejor categoría: política (confianza: 0.7970)\n",
            "Top 3 categorías:\n",
            "  - política: 0.7970\n",
            "  - economía: 0.0626\n",
            "  - salud: 0.0521\n",
            "\n",
            "Texto: El nuevo modelo de IA supera a los anteriores\n",
            "Mejor categoría: tecnología (confianza: 0.7536)\n",
            "Top 3 categorías:\n",
            "  - tecnología: 0.7536\n",
            "  - política: 0.1247\n",
            "  - economía: 0.0607\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ejemplo práctico: Clasificación Zero-Shot\n",
        "\n",
        "La clasificación zero-shot permite clasificar texto en categorías personalizadas\n",
        "sin necesidad de entrenar un modelo. Es muy útil cuando no tienes datos etiquetados.\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Crear pipeline de clasificación zero-shot\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "# Textos a clasificar\n",
        "textos = [\n",
        "    \"El equipo ganó el partido 3-0 en el último minuto\",\n",
        "    \"La nueva ley fue aprobada por el congreso\",\n",
        "    \"El nuevo modelo de IA supera a los anteriores\",\n",
        "]\n",
        "\n",
        "# Categorías posibles\n",
        "categorias = [\"deportes\", \"política\", \"tecnología\", \"economía\", \"salud\"]\n",
        "\n",
        "print(\"Clasificación Zero-Shot:\\n\")\n",
        "for texto in textos:\n",
        "    result = classifier(texto, candidate_labels=categorias)\n",
        "    print(f\"Texto: {texto}\")\n",
        "    print(\n",
        "        f\"Mejor categoría: {result['labels'][0]} (confianza: {result['scores'][0]:.4f})\"\n",
        "    )\n",
        "    print(\"Top 3 categorías:\")\n",
        "    for label, score in zip(result[\"labels\"][:3], result[\"scores\"][:3]):\n",
        "        print(f\"  - {label}: {score:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3. Generación de Resúmenes\n",
        "\n",
        "Los modelos de resumen pueden condensar texto largo en versiones más cortas manteniendo la información clave.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto original:\n",
            "\n",
            "La inteligencia artificial (IA) ha revolucionado numerosos campos en las últimas décadas.\n",
            "Desde el reconocimiento de imágenes hasta el procesamiento de lenguaje natural, los avances\n",
            "han sido extraordinarios. Los modelos de aprendizaje profundo, especialmente los transformers,\n",
            "han permitido avances significativos en tareas que antes eran consideradas imposibles para las máquinas.\n",
            "\n",
            "Hugging Face ha desempeñado un papel crucial en la democratización de la IA, proporcionando\n",
            "acceso a miles de modelos pre-entrenados que pueden ser utilizados por investigadores y\n",
            "desarrolladores de todo el mundo. Esto ha acelerado la innovación y ha hecho que la IA sea\n",
            "más accesible para personas sin recursos computacionales masivos.\n",
            "\n",
            "El futuro de la IA promete aún más avances, con modelos cada vez más grandes y capaces,\n",
            "pero también con un enfoque creciente en la eficiencia y la accesibilidad.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Resumen generado:\n",
            "La inteligencia artificial (IA) ha revolucionado numerosos campos. Esto ha acelerado la innovación. La IA sea más accesible para personas sin recursos computacionales masivos.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ejemplo práctico: Generación de Resúmenes\n",
        "\n",
        "Los modelos de resumen automático pueden condensar textos largos en versiones\n",
        "más cortas manteniendo la información más importante.\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Crear pipeline de resumen\n",
        "# Nota: Este modelo puede tardar en cargar la primera vez\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Texto largo a resumir (ejemplo sobre inteligencia artificial)\n",
        "texto_largo = \"\"\"\n",
        "La inteligencia artificial (IA) ha revolucionado numerosos campos en las últimas décadas.\n",
        "Desde el reconocimiento de imágenes hasta el procesamiento de lenguaje natural, los avances\n",
        "han sido extraordinarios. Los modelos de aprendizaje profundo, especialmente los transformers,\n",
        "han permitido avances significativos en tareas que antes eran consideradas imposibles para las máquinas.\n",
        "\n",
        "Hugging Face ha desempeñado un papel crucial en la democratización de la IA, proporcionando\n",
        "acceso a miles de modelos pre-entrenados que pueden ser utilizados por investigadores y\n",
        "desarrolladores de todo el mundo. Esto ha acelerado la innovación y ha hecho que la IA sea\n",
        "más accesible para personas sin recursos computacionales masivos.\n",
        "\n",
        "El futuro de la IA promete aún más avances, con modelos cada vez más grandes y capaces,\n",
        "pero también con un enfoque creciente en la eficiencia y la accesibilidad.\n",
        "\"\"\"\n",
        "\n",
        "# Generar resumen\n",
        "print(\"Texto original:\")\n",
        "print(texto_largo)\n",
        "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "\n",
        "summary = summarizer(texto_largo, max_length=100, min_length=30, do_sample=False)\n",
        "print(\"Resumen generado:\")\n",
        "print(summary[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4. Análisis de Sentimientos con Modelo en Español\n",
        "\n",
        "Para textos en español, podemos usar modelos específicamente entrenados en español para mejores resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e471619dac7845898d1d4b0ec8e33925",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "124956431a5547008568ccf8763af80b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf212f149ab7478d952790cd7e6005ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed1b1165fc0b4c27850eacfd93f0f2d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5d05eb25fc341179972d1671be0c908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Análisis de Sentimientos en Español:\n",
            "\n",
            "Texto: Este producto es excelente, lo recomiendo totalmente\n",
            "Resultado: 5 stars (confianza: 0.7752)\n",
            "\n",
            "Texto: No estoy satisfecho con la calidad del servicio\n",
            "Resultado: 2 stars (confianza: 0.4958)\n",
            "\n",
            "Texto: La película fue entretenida pero nada del otro mundo\n",
            "Resultado: 3 stars (confianza: 0.4856)\n",
            "\n",
            "Texto: ¡Increíble! Superó todas mis expectativas\n",
            "Resultado: 5 stars (confianza: 0.9232)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ejemplo práctico: Análisis de Sentimientos en Español\n",
        "\n",
        "Para obtener mejores resultados con textos en español, podemos usar modelos\n",
        "específicamente entrenados en español. Hugging Face tiene varios modelos disponibles.\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Usar un modelo específico para español\n",
        "# Este modelo está optimizado para análisis de sentimientos en español\n",
        "sentiment_es = pipeline(\n",
        "    \"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        ")\n",
        "\n",
        "# Textos en español para analizar\n",
        "textos_es = [\n",
        "    \"Este producto es excelente, lo recomiendo totalmente\",\n",
        "    \"No estoy satisfecho con la calidad del servicio\",\n",
        "    \"La película fue entretenida pero nada del otro mundo\",\n",
        "    \"¡Increíble! Superó todas mis expectativas\",\n",
        "]\n",
        "\n",
        "print(\"Análisis de Sentimientos en Español:\\n\")\n",
        "for texto in textos_es:\n",
        "    result = sentiment_es(texto)\n",
        "    print(f\"Texto: {texto}\")\n",
        "    print(f\"Resultado: {result[0]['label']} (confianza: {result[0]['score']:.4f})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5. Extracción de Respuestas (Question Answering)\n",
        "\n",
        "Los modelos de question answering pueden responder preguntas basándose en un contexto dado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ecd0e955b442568cac29f0819633c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c3c0a6761ae424a9c0e04cbafe7bf75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681e1c59d2404efea5de535a342f99db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fd39cf99c98405bb5f74ed45a3839e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681367a1ddec4834a658d9d22f7ec725",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question Answering:\n",
            "\n",
            "Contexto: \n",
            "Hugging Face es una plataforma de código abierto que proporciona herramientas\n",
            "y modelos de inteligencia artificial, especialmente para procesamiento de lenguaje natural.\n",
            "La plataforma fue fundada en 2016 y se ha convertido en el estándar de la industria\n",
            "para compartir y usar modelos de IA pre-entrenados. Ofrece miles de modelos gratuitos\n",
            "que pueden ser utilizados para tareas como análisis de sentimientos, traducción,\n",
            "generación de texto y muchas otras aplicaciones.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Pregunta: ¿Qué es Hugging Face?\n",
            "Respuesta: una plataforma de código abierto\n",
            "Confianza: 0.0824\n",
            "Posición en el texto: 17-49\n",
            "\n",
            "Pregunta: ¿Cuándo fue fundada Hugging Face?\n",
            "Respuesta: 2016 y se ha convertido\n",
            "Confianza: 0.0478\n",
            "Posición en el texto: 200-223\n",
            "\n",
            "Pregunta: ¿Qué tipo de modelos ofrece Hugging Face?\n",
            "Respuesta: modelos de inteligencia artificial\n",
            "Confianza: 0.0099\n",
            "Posición en el texto: 81-115\n",
            "\n",
            "Pregunta: ¿Para qué se pueden usar los modelos de Hugging Face?\n",
            "Respuesta: Ofrece miles de modelos gratuitos\n",
            "Confianza: 0.0668\n",
            "Posición en el texto: 307-340\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ejemplo práctico: Question Answering\n",
        "\n",
        "Los modelos de question answering pueden responder preguntas basándose en un\n",
        "contexto proporcionado. Esto es útil para sistemas de búsqueda, chatbots, etc.\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Crear pipeline de question answering\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "# Contexto sobre el que se harán las preguntas\n",
        "contexto = \"\"\"\n",
        "Hugging Face es una plataforma de código abierto que proporciona herramientas\n",
        "y modelos de inteligencia artificial, especialmente para procesamiento de lenguaje natural.\n",
        "La plataforma fue fundada en 2016 y se ha convertido en el estándar de la industria\n",
        "para compartir y usar modelos de IA pre-entrenados. Ofrece miles de modelos gratuitos\n",
        "que pueden ser utilizados para tareas como análisis de sentimientos, traducción,\n",
        "generación de texto y muchas otras aplicaciones.\n",
        "\"\"\"\n",
        "\n",
        "# Preguntas a responder\n",
        "preguntas = [\n",
        "    \"¿Qué es Hugging Face?\",\n",
        "    \"¿Cuándo fue fundada Hugging Face?\",\n",
        "    \"¿Qué tipo de modelos ofrece Hugging Face?\",\n",
        "    \"¿Para qué se pueden usar los modelos de Hugging Face?\",\n",
        "]\n",
        "\n",
        "print(\"Question Answering:\\n\")\n",
        "print(f\"Contexto: {contexto}\\n\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "for pregunta in preguntas:\n",
        "    result = qa_pipeline(question=pregunta, context=contexto)\n",
        "    print(f\"Pregunta: {pregunta}\")\n",
        "    print(f\"Respuesta: {result['answer']}\")\n",
        "    print(f\"Confianza: {result['score']:.4f}\")\n",
        "    print(f\"Posición en el texto: {result['start']}-{result['end']}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bluemath-dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
